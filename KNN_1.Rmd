---
title: "KNN(k-nearest-neighbors)"
author: "lee je seok"
date: '2020 9 24 '
output: html_document
editor_options: 
  chunk_output_type: console
---

# KNN K근접 이웃 알고리즘

class library에 존재하는 'knn' function을 사용

추가로, 'caret' library에서 parameter를 tuning함

knn은 k만을 parameter로 가짐, distance(거리) 계산하여 예측

그래서 KNN을 non-parametric, supervised learning algorithm이라 함.

### 주의할 것
* knn사용시 feature에 categorical variable이 없야함. -> 거리를 계산 할 수 없음
* 훈련 데이터가 high-demensional인 경우, knn 다차원의 저주 발생 -> knn실행 전에 차원 축소
* 훈련 데이터를 표준화함. -> 각 feature의 평균 : 0, 표준편자 : 1

## library
```{r}
library(class)
library(caret)
require(mlbench)
library(e1071)
library(base)
require(base)
```

<br>
<br>

## 1. 데이터 준비
```{r}
#Sonar 데이터 이용
data(Sonar)
head(Sonar)
```

## 2-1. 데이터 파악
```{r}
cat('행의 수, 열의수 : ', nrow(Sonar), ncol(Sonar))
# Sonar Class의 범주별 개수 확인
table(Sonar$Class)
# 열별 결측값의 개수 확인
apply(Sonar, 2, function(x) sum(is.na(x)))
```

## 2-2. 데이터 split
```{r}
#Sonar data를 무작위로 섞음
data <- Sonar[sample(nrow(Sonar)),]
#train data와 test data로 split할 비율
bound <- floor(0.7 * nrow(data))
#train, test로 data split
df_train <- data[1:bound, ]
df_test <- data[(bound + 1) : nrow(data), ]
cat('training data와 test data의 sample 수', nrow(df_train), nrow(df_test))

X_train <- subset(df_train, select = -Class)
y_train <- df_train$Class
X_test <- subset(df_test, select = -Class)
y_test <- df_test$Class
```

## 3. 모델 학습
```{r}
model_knn <- knn(train = X_train,
                 test = X_test, 
                 cl = y_train, #label
                 k = 3) #X_train, y_train을 이용 -> X_test에 대한 category 예측
model_knn
```

## 4. 모델 성능 평가
```{r}
conf_mat <- table(y_test, model_knn)

#confusion matrix
conf_mat

cat('Test accuracy : ', sum(diag(conf_mat))/ sum(conf_mat))

#k = 3인 model이 overfitting/underfitting인지, 좋은 choice인지 -> Leave one out cross validation(LOOCV)
knn_loocv <- knn.cv(train = X_train, cl = y_train, k = 3)
knn_loocv

#confusion matrix
conf_mat_cv <- table(y_train, knn_loocv)
conf_mat_cv
cat('LOOCV accuracy : ', sum(diag(conf_mat_cv))/ sum(conf_mat_cv))

#성능이 그리 좋지 않음 -> k 값을 바꾸는게 더 좋아 보임
```

* 교차 검증(cross validation) : 전체 데이터 셋을 k개로 나눈 후 k 번의 성능 평가를 함, 이때 test set을 중복 없이 바꿔가면서 평가
k개의 평가 지표의 평균을 내어 최종적으로 모델의 성능을 평가함

* 장점
1. 모든 데이터 셋을 평가에 활용 가능 -> 일반화된 모델을 만들 수 있음. overfitting 방지
2. 모든 데이터 셋을 훈련에 활용 가능 -> 정확도 향상, underfitting 방지

* 단점
iteration 횟수가 많아서 모델 훈련/평가에 시간이 오래 걸림

## 5. 모델 성능 향상
'caret' library를 이용해서 cross-validation을 수행하고 적절한 k값을 고름
```{r}
# train 데이터, test 데이터 생성 (위의 2보다 간편)
in_train <- createDataPartition(Sonar$Class, p = 0.7, list = FALSE) 
ndf_train <- Sonar[in_train,]
ndf_test <- Sonar[-in_train,]

#5-fold cross validation 을 2번 반복
ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 2)

nn_grid <- expand.grid(k = c(1,3,5,7))
nn_grid

best_knn <- train(Class ~ ., data = ndf_train,
                  method = 'knn',
                  trControl = ctrl,
                  preProcess = c('center','scale'),
                  tuneGrid = nn_grid)
best_knn
```

## Demensionality reduction
테스트 정확도 향상
'caret' library -> 'confusionMatrix' function으로  95신뢰구간, accuracy 확인
```{r}
ctrl <- trainControl(method = 'repeatedcv', number = 5, repeats = 5)
nn_grid <- expand.grid(k = c(1,3,5,7))
best_knn_reduced <- train(Class ~., data = ndf_train, method = 'knn', trControl = ctrl, preProcess = c('center','scale','YeoJohnson')) #YeoJohnson -> BoxCox의 확장
X_test <- subset(ndf_test, select = -Class)
pred_reduced <- predict(best_knn_reduced, newdata = X_test, model = 'best')
conf_mat_best_reduced <- confusionMatrix(ndf_test$Class, pred_reduced)
conf_mat_best_reduced
```



